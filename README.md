# First Workshop on Uncertainty-Aware NLP @EACL 2024

Welcome to the website of the **UncertaiNLP** workshop to be held at EACL 2024 in Malta.

*website under construction* 

## Workshop Topic and Content

Human languages are inherently ambiguous and understanding language input is subject to interpretation and complex contextual dependencies. Nevertheless, the main body of research in NLP is still based on the assumption that ambiguities and other types of underspecification can and have to be re-solved. This workshop will provide a platform for research that embraces variability in human language and aims to represent and evaluate the uncertainty that arises from it, and from modeling tools themselves.

### Workshop Topics

UncertaiNLP welcomes submissions to topics related (but not limited) to:

- *Frameworks for uncertainty representation*
  - Theoretical work on probability and its generalizations
  - Symbolic representations of uncertainty
- *Documenting sources of uncertainty*
  - Theoretical underpinnings of linguistic sources of variation
  - Data collection (e.g., to to document linguistic variability, multiple perspectives, etc.)
 
- *Modeling*
  - Explicit representation of model uncertainty (e.g., parameter and/or hypothesis uncertainty, Bayesian NNs in NLU/NLG, verbalised uncertainty, feature density, external calibration modules)
  - Disentangled representation of different sources of uncertainty (e.g., hierarchical models, prompting)
  - Reducing uncertainty due to additional context (e.g., additional context, clarification questions, retrieval/API augmented models)

- *Learning (or parameter estimation)*
  - Learning from single and/or multiple references
  - Gradient estimation in latent variable models
 
- *Probabilistic inference*
  - Theoretical and applied work on approximate inference (e.g., variational inference, Langevin dynamics)
  - Unbiased and asymptotically unbiased sampling algorithms
 
- *Decision making*
  - Utility-aware decoders and controllable generation
  - Selective prediction
  - Active learning
    
- *Evaluation*
  - Statistical evaluation of language models
  - Calibration to interpretable notions of uncertainty (e.g., calibration error, conformal prediction)
  - Evaluation of epistemic uncertainty
 
## Workshop Organizer

- [Wilker Aziz, University of Amsterdam](https://wilkeraziz.github.io/)
- [Joris Baan, University of Amsterdam](https://jorisbaan.nl/)
- [Hande Celikkanat, University of Helsinki](https://researchportal.helsinki.fi/en/persons/hande-celikkanat)
- [Marie-Catherine de Marneffe, UCLouvain and FNRS](https://www.asc.ohio-state.edu/demarneffe.1/)
- [Barbara Plank, LMU Munich and IT University of Copenhagen](bplank.github.io/)
- [Swabha Swayamdipta, USC Viterbi CS](https://swabhs.com/)
- [JÃ¶rg Tiedemann, University of Helsinki](https://blogs.helsinki.fi/tiedeman/)
- [Dennis Ulmer, IT University of Copenhagen](https://dennisulmer.eu/)
 
    
